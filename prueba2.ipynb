{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song_file(cur, filepath):\n",
    "    \"\"\"This Function reads the json files, transform and insert the artists and their songs.\"\"\"\n",
    "    # open song file\n",
    "    df =  pd.read_json(filepath, lines=True) \n",
    "\n",
    "    # insert artist record\n",
    "    artist_data_col =  ['artist_id'  , 'artist_name'  , 'artist_location'  , 'artist_latitude'  , 'artist_longitude']\n",
    "    artist_data = df[artist_data_col].drop_duplicates()\n",
    "   \n",
    "    for i, row in artist_data.iterrows():\n",
    "        cur.execute(artist_table_insert, row)  \n",
    "  \n",
    "    \n",
    "    # insert song record\n",
    "    song_cols = [\"song_id\", \"title\", \"year\", \"duration\"]\n",
    "    song_data = df[song_cols].drop_duplicates()\n",
    "    \n",
    "    for i, row in song_data.iterrows():\n",
    "        cur.execute(song_table_insert, row)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_log_file(cur, filepath):\n",
    "    \"\"\"This Function reads the json files, transform and insert the users, time and the fact table \"\"\"\n",
    "    # open log file\n",
    "    df = pd.read_json(filepath, lines = True)\n",
    "\n",
    "    # filter by NextSong action\n",
    "    df = df[df['page'] == 'NextSong']\n",
    "\n",
    "\n",
    "    # convert timestamp column to datetime\n",
    "    t = pd.to_datetime(df['ts'], unit='ms')\n",
    "    \n",
    "    # insert time data records\n",
    "    time_data = (t.tolist(),t.dt.hour.values.tolist(),t.dt.day.values.tolist(),\n",
    "                 t.dt.week.values.tolist(),t.dt.month.values.tolist(),\n",
    "                 t.dt.year.values.tolist(),t.dt.weekday.values.tolist())\n",
    "    column_labels = column_labels = ('start_time', 'hour', 'day', 'week', 'month', 'year', 'weekday')\n",
    "    data = {column_labels[i]:time_data[i] for i in range(len(column_labels))}\n",
    "    time_df = pd.DataFrame(data=data)\n",
    "    \n",
    "    for i, row in time_df.iterrows():\n",
    "        cur.execute(time_table_insert, list(row))\n",
    "\n",
    "    \n",
    "    # load user table\n",
    "    user_column_labels = ['userId', 'firstName', 'lastName', 'gender','level']\n",
    "    user_df = df[user_column_labels].drop_duplicates()\n",
    "\n",
    "\n",
    "    # insert user records\n",
    "    for i, row in user_df.iterrows():\n",
    "        cur.execute(user_table_insert, row)  \n",
    "        \n",
    "\n",
    "    # insert songplay records\n",
    "    column_labels = ['ts', 'userId', 'sessionId', 'location','userAgent']\n",
    "    songplay_df = df[column_labels].drop_duplicates()\n",
    "\n",
    "    for index, row in songplay_df.iterrows():\n",
    "        \n",
    "        # get songid and artistid from song and artist tables\n",
    "        cur.execute(song_select)\n",
    "        results = cur.fetchone()\n",
    "        \n",
    "        cur.execute(artist_select)\n",
    "        results_2 = cur.fetchone()\n",
    "   \n",
    "        if results:\n",
    "            songid = results\n",
    "            \n",
    "        else:\n",
    "            songid = None\n",
    "\n",
    "        if results_2:\n",
    "            artistid = results_2\n",
    "            \n",
    "        else:\n",
    "            artistid = None\n",
    "        \n",
    "        \n",
    "        # insert songplay record\n",
    "        songplay_data = (t[index], row['userId'], songid,artistid, row['sessionId'], row['location'], row['userAgent'] )\n",
    "        cur.execute(songplay_table_insert, songplay_data)   \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(cur, conn, filepath, func):\n",
    "    \"\"\"This function reads all files in json format that are found in the data folders and will allow each file to be processed to be ingested in the corresponding table\"\"\"\n",
    "    \n",
    "    # get all files matching extension from directory\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "\n",
    "    # get total number of files found\n",
    "    num_files = len(all_files)\n",
    "    print('{} files found in {}'.format(num_files, filepath))\n",
    "\n",
    "    # iterate over files and process\n",
    "    for i, datafile in enumerate(all_files, 1):\n",
    "        func(cur, datafile)\n",
    "        conn.commit()\n",
    "        print('{}/{} files processed.'.format(i, num_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"this function will ingest in the database sparkifydb, assuming that the tables (dimensions and table of facts) are already created\"\"\"\n",
    "    \n",
    "    #Connection with the Database sparkfydb in Postgres using student credencials\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    #Ingest the tables from song_data directory\n",
    "    process_data(cur, conn, filepath='data/song_data', func=process_song_file)\n",
    "    \n",
    "    #Ingest the tables from log_data directory\n",
    "    process_data(cur, conn, filepath='data/log_data', func=process_log_file)\n",
    "\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 files found in data/song_data\n",
      "1/71 files processed.\n",
      "2/71 files processed.\n",
      "3/71 files processed.\n",
      "4/71 files processed.\n",
      "5/71 files processed.\n",
      "6/71 files processed.\n",
      "7/71 files processed.\n",
      "8/71 files processed.\n",
      "9/71 files processed.\n",
      "10/71 files processed.\n",
      "11/71 files processed.\n",
      "12/71 files processed.\n",
      "13/71 files processed.\n",
      "14/71 files processed.\n",
      "15/71 files processed.\n",
      "16/71 files processed.\n",
      "17/71 files processed.\n",
      "18/71 files processed.\n",
      "19/71 files processed.\n",
      "20/71 files processed.\n",
      "21/71 files processed.\n",
      "22/71 files processed.\n",
      "23/71 files processed.\n",
      "24/71 files processed.\n",
      "25/71 files processed.\n",
      "26/71 files processed.\n",
      "27/71 files processed.\n",
      "28/71 files processed.\n",
      "29/71 files processed.\n",
      "30/71 files processed.\n",
      "31/71 files processed.\n",
      "32/71 files processed.\n",
      "33/71 files processed.\n",
      "34/71 files processed.\n",
      "35/71 files processed.\n",
      "36/71 files processed.\n",
      "37/71 files processed.\n",
      "38/71 files processed.\n",
      "39/71 files processed.\n",
      "40/71 files processed.\n",
      "41/71 files processed.\n",
      "42/71 files processed.\n",
      "43/71 files processed.\n",
      "44/71 files processed.\n",
      "45/71 files processed.\n",
      "46/71 files processed.\n",
      "47/71 files processed.\n",
      "48/71 files processed.\n",
      "49/71 files processed.\n",
      "50/71 files processed.\n",
      "51/71 files processed.\n",
      "52/71 files processed.\n",
      "53/71 files processed.\n",
      "54/71 files processed.\n",
      "55/71 files processed.\n",
      "56/71 files processed.\n",
      "57/71 files processed.\n",
      "58/71 files processed.\n",
      "59/71 files processed.\n",
      "60/71 files processed.\n",
      "61/71 files processed.\n",
      "62/71 files processed.\n",
      "63/71 files processed.\n",
      "64/71 files processed.\n",
      "65/71 files processed.\n",
      "66/71 files processed.\n",
      "67/71 files processed.\n",
      "68/71 files processed.\n",
      "69/71 files processed.\n",
      "70/71 files processed.\n",
      "71/71 files processed.\n",
      "30 files found in data/log_data\n",
      "1/30 files processed.\n",
      "2/30 files processed.\n",
      "3/30 files processed.\n",
      "4/30 files processed.\n",
      "5/30 files processed.\n",
      "6/30 files processed.\n",
      "7/30 files processed.\n",
      "8/30 files processed.\n",
      "9/30 files processed.\n",
      "10/30 files processed.\n",
      "11/30 files processed.\n",
      "12/30 files processed.\n",
      "13/30 files processed.\n",
      "14/30 files processed.\n",
      "15/30 files processed.\n",
      "16/30 files processed.\n",
      "17/30 files processed.\n",
      "18/30 files processed.\n",
      "19/30 files processed.\n",
      "20/30 files processed.\n",
      "21/30 files processed.\n",
      "22/30 files processed.\n",
      "23/30 files processed.\n",
      "24/30 files processed.\n",
      "25/30 files processed.\n",
      "26/30 files processed.\n",
      "27/30 files processed.\n",
      "28/30 files processed.\n",
      "29/30 files processed.\n",
      "30/30 files processed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
